{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, \"/share/home/ychi/dev/sperm_struct/notebooks\")\n",
    "\n",
    "import h2 as h\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hic_basic.binnify import GenomeIdeograph\n",
    "from hic_basic.data import chromosomes, dupref_annote, fetch_cent_chromlen\n",
    "from hic_basic.hicio import dump_pickle, load_pickle\n",
    "from hic_basic.plot.render import centelo_relpos\n",
    "from hic_basic.sequence import count_CpG\n",
    "from hires_utils.hires_io import s2m_index, m2s_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Force = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare features and aggs for mm10 genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate features(pd.DataFrame) and aggs(dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare base index\n",
    "mm10 = GenomeIdeograph(\"mm10\")\n",
    "bins = mm10.bins(20e3,bed=True,order=True, flavor=\"hickit\")\n",
    "features = bins.set_index([\"chrom\",\"start\"]).drop(\"end\",axis=1).copy()\n",
    "\n",
    "agg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding CpG density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shareb/ychi/repo/sperm_struct/notebooks/data2/mm10.CpG.20k.tsv.gz exists, skipping\n"
     ]
    }
   ],
   "source": [
    "Fin = False\n",
    "outfile = h.ddir / \"mm10.CpG.20k.tsv.gz\"\n",
    "if (not outfile.exists() or Force) and (not Fin):\n",
    "    CpG = count_CpG(\n",
    "        bins,\n",
    "        \"/share/Data/ychi/genome/GRCm38/raw/mm10.fa\"\n",
    "    )\n",
    "\n",
    "    CpG.to_csv(\n",
    "        outfile,\n",
    "        index=False,\n",
    "        header=False,\n",
    "        sep=\"\\t\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"{outfile} exists, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CpG = pd.read_table(\n",
    "    h.ddir / \"mm10.CpG.20k.tsv.gz\",\n",
    "    names = [\"chrom\", \"start\", \"end\",\"CpG\"],\n",
    "    index_col = [\"chrom\", \"start\"]\n",
    ").drop(\"end\",axis=1)\n",
    "\n",
    "# strict left\n",
    "features = pd.concat([features,CpG],axis=1,join=\"outer\").loc[features.index]\n",
    "\n",
    "agg.update(\n",
    "    {\"mean_CpG\" : (\"CpG\", \"mean\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10    0.00405\n",
       "0.50    0.00730\n",
       "0.90    0.01375\n",
       "0.95    0.01595\n",
       "Name: CpG, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CpG[\"CpG\"].quantile([0.1,0.5,0.9,0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding chromosome distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm10 = chromosomes(\"mm10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.assign(**dict.fromkeys(mm10.index,0))\n",
    "for chrom in mm10.index:\n",
    "    features.loc[chrom,chrom] = 1\n",
    "\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [chrom+\"_dist\" for chrom in mm10.index],\n",
    "        [(chrom,\"sum\") for chrom in mm10.index]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.assign(particle=1)\n",
    "\n",
    "agg.update(\n",
    "    {\"density\" : (\"particle\", \"sum\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding per-sample depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #depths_df = pd.read_parquet(\"/share/home/ychi/data/notebook/dailyT/sperm25/depth.parquet\")\n",
    "# depths_df = pd.read_parquet(\"/share/home/ychi/data/notebook/dailyT/sperm25/real_depth.parquet\")\n",
    "\n",
    "# agg.update(\n",
    "#     {\n",
    "#         \"mean_depth\" : (\"depth\",\"mean\")\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding centelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "relpos = centelo_relpos(s2m_index(features.index), \"mm10\")\n",
    "relpos.columns = [\"chrom\",\"pos\",\"centelo\"]\n",
    "relpos = relpos.set_index([\"chrom\",\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relpos = relpos.loc[~relpos.index.get_level_values(0).isin([\"chrX\",\"chrY\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([features,m2s_index(relpos)],axis=1,join=\"outer\").loc[features.index]\n",
    "agg.update(\n",
    "    {\"mean_centelo\" : (\"centelo\", \"mean\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding extrem centelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_index(inplace=True)\n",
    "# orig_features = features.copy() # just backup\n",
    "features = s2m_index(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [0.5e6,1e6,2e6,5e6,10e6]\n",
    "p, q = False, True\n",
    "centelo = fetch_cent_chromlen(\"mm10\")\n",
    "centelo_cols = []\n",
    "for dis in dists:\n",
    "    centelo_col = \"%.1f\" % (dis/1e6) + \"M_centelo\"\n",
    "    centelo_cols.append(centelo_col)\n",
    "    features = features.assign(**{centelo_col:0})\n",
    "    for chrom in centelo.index:\n",
    "        if chrom.startswith(\"chrX\") or chrom.startswith(\"chrY\"):\n",
    "            continue\n",
    "        cent_start, cent_end = centelo.loc[chrom, [\"start\",\"end\"]]\n",
    "        # arm1 paracentric\n",
    "        if p:\n",
    "            features.loc[(chrom, cent_start-dis):(chrom, cent_start), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            # arm2 paracentric\n",
    "            features.loc[(chrom, cent_end):(chrom, cent_end+dis), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        start, end = 0, centelo.loc[chrom, \"chrom_length\"]\n",
    "        # arm1 near telomere\n",
    "        if p:\n",
    "            features.loc[(chrom, start):(chrom, start+dis), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            features.loc[(chrom, end-dis):(chrom, end), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"sum\") for i in centelo_cols]\n",
    "    ))\n",
    ")\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_mean_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"mean\") for i in centelo_cols]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = m2s_index(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add separate extreme centelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = s2m_index(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [0.5e6,1e6,2e6,5e6,10e6]\n",
    "p, q = False, True\n",
    "centelo = fetch_cent_chromlen(\"mm10\")\n",
    "centelo_cols = []\n",
    "for dis in dists:\n",
    "    centelo_col = \"%.1f\" % (dis/1e6) + \"M_cent\"\n",
    "    centelo_cols.append(centelo_col)\n",
    "    features = features.assign(**{centelo_col:0})\n",
    "    for chrom in centelo.index:\n",
    "        if chrom.startswith(\"chrX\") or chrom.startswith(\"chrY\"):\n",
    "            continue\n",
    "        cent_start, cent_end = centelo.loc[chrom, [\"start\",\"end\"]]\n",
    "        # arm1 paracentric\n",
    "        if p:\n",
    "            features.loc[(chrom, cent_start-dis):(chrom, cent_start), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            # arm2 paracentric\n",
    "            features.loc[(chrom, cent_end):(chrom, cent_end+dis), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "for dis in dists:\n",
    "    centelo_col = \"%.1f\" % (dis/1e6) + \"M_telo\"\n",
    "    centelo_cols.append(centelo_col)\n",
    "    features = features.assign(**{centelo_col:0})\n",
    "    for chrom in centelo.index:\n",
    "        if chrom.startswith(\"chrX\") or chrom.startswith(\"chrY\"):\n",
    "            continue\n",
    "        start, end = 0, centelo.loc[chrom, \"chrom_length\"]\n",
    "        # arm1 near telomere\n",
    "        if p:\n",
    "            features.loc[(chrom, start):(chrom, start+dis), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            features.loc[(chrom, end-dis):(chrom, end), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"sum\") for i in centelo_cols]\n",
    "    ))\n",
    ")\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_mean_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"mean\") for i in centelo_cols]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = m2s_index(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add centelo scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.assign(\n",
    "    **{\n",
    "        \"5.0Mto10.0M_telo\" : features[\"10.0M_telo\"] - features[\"5.0M_telo\"],\n",
    "        \"5.0Mto10.0M_cent\" : features[\"10.0M_cent\"] - features[\"5.0M_cent\"]\n",
    "        }\n",
    ")\n",
    "agg.update(\n",
    "    {\n",
    "        \"5.0Mto10.0M_telo_dist\" : (\"5.0Mto10.0M_telo\", \"sum\"),\n",
    "        \"5.0Mto10.0M_cent_dist\" : (\"5.0Mto10.0M_cent\", \"sum\")\n",
    "        }\n",
    ")\n",
    "agg.update(\n",
    "    {\n",
    "        \"5.0Mto10.0M_telo_mean_dist\" : (\"5.0Mto10.0M_telo\", \"mean\"),\n",
    "        \"5.0Mto10.0M_cent_mean_dist\" : (\"5.0Mto10.0M_cent\", \"mean\")\n",
    "        }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add bulk A and B compartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pd.read_table(h.ddir / \"Sperm.cis.vecs.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hic_basic.compartment import AB_block_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.assign(\n",
    "    bulkA = 0,\n",
    "    bulkB = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in AB_block_ends(vec).iterrows():\n",
    "    if row[\"AB\"] == \"A\":\n",
    "        features.loc[(row[\"chrom\"],row[\"start\"]):(row[\"chrom\"],row[\"end\"]),\"bulkA\"] = 1\n",
    "    elif row[\"AB\"] == \"B\":\n",
    "        features.loc[(row[\"chrom\"],row[\"start\"]):(row[\"chrom\"],row[\"end\"]),\"bulkB\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.update(\n",
    "    {\n",
    "        \"bulkA_dist\" : (\"bulkA\", \"sum\"),\n",
    "        \"bulkB_dist\" : (\"bulkB\", \"sum\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0327, half bin\n",
    "features.to_csv(h.ddir/\"mm10.features.csv.gz\")\n",
    "dump_pickle(agg,h.ddir/\"mm10.aggs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare features for Sperm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\n",
    "    h.ddir/\"mm10.features.csv.gz\",\n",
    "    index_col=[0,1]\n",
    ")\n",
    "features.index.names = [\"chrom\",\"start\"]\n",
    "aggs = load_pickle(h.ddir/\"mm10.aggs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding 1M intermingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/shareb/ychi/repo/sperm_struct/notebooks/data2/Sperm.intermingling.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m intermingling \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSperm.intermingling.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m intermingling\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchrom\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoarsen_start\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#1M reso\u001b[39;00m\n\u001b[1;32m      7\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:265\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    273\u001b[0m         path_or_handle,\n\u001b[1;32m    274\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    278\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:139\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    129\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/shareb/ychi/repo/sperm_struct/notebooks/data2/Sperm.intermingling.parquet'"
     ]
    }
   ],
   "source": [
    "intermingling = pd.read_parquet(\n",
    "    h.ddir / \"Sperm.intermingling.parquet\"\n",
    ")\n",
    "intermingling.index.names = [\n",
    "    \"chrom\",\n",
    "    \"coarsen_start\" #1M reso\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper = GenomeIdeograph(\"mm10\").coarsen_grouper(20000, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.merge(\n",
    "    features.assign(\n",
    "        coarsen_start = grouper.apply(lambda x : x[1])\n",
    "    ).reset_index(),\n",
    "    intermingling.reset_index(),\n",
    "    on=[\"chrom\",\"coarsen_start\"],\n",
    "    how=\"left\"\n",
    ").drop(\"coarsen_start\",axis=1).set_index([\"chrom\",\"start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs.update(\n",
    "    {\n",
    "        \"mean_intermingling_ratio\" : (\"intermingling_ratio\", \"mean\"),\n",
    "        \"mean_multi_chrom_intermingling\" : (\"multi_chrom_intermingling\", \"mean\"),\n",
    "        \"mean_species_richness\" : (\"species_richness\", \"mean\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(\n",
    "    h.ddir / \"Sperm.mm10.features.csv.gz\",\n",
    "    index=True\n",
    ")\n",
    "dump_pickle(aggs, h.ddir/\"Sperm.mm10.aggs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare features and aggs for mm10_dip genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate features(pd.DataFrame) and aggs(dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare base index\n",
    "mm10_dip = GenomeIdeograph(\"mm10_dip\")\n",
    "bins = mm10_dip.bins(20e3,bed=True,order=True,flavor=\"hickit\")\n",
    "features = bins.set_index([\"chrom\",\"start\"]).drop(\"end\",axis=1).copy()\n",
    "\n",
    "agg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding CpG density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CpG = pd.read_table(\n",
    "    h.ddir / \"mm10.CpG.20k.tsv.gz\",\n",
    "    names = [\"chrom\", \"start\", \"end\",\"CpG\"],\n",
    "    index_col = [\"chrom\", \"start\"]\n",
    ").drop(\"end\",axis=1)\n",
    "\n",
    "# strict left\n",
    "features = dupref_annote(features, CpG)\n",
    "\n",
    "agg.update(\n",
    "    {\"mean_CpG\" : (\"CpG\", \"mean\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10    0.00405\n",
       "0.50    0.00730\n",
       "0.90    0.01375\n",
       "0.95    0.01595\n",
       "Name: CpG, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CpG[\"CpG\"].quantile([0.1,0.5,0.9,0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding chromosome distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm10_dip = chromosomes(\"mm10_dip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.assign(**dict.fromkeys(mm10_dip.index,0))\n",
    "for chrom in mm10_dip.index:\n",
    "    features.loc[chrom,chrom] = 1\n",
    "\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [chrom+\"_dist\" for chrom in mm10_dip.index],\n",
    "        [(chrom,\"sum\") for chrom in mm10_dip.index]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.assign(particle=1)\n",
    "\n",
    "agg.update(\n",
    "    {\"density\" : (\"particle\", \"sum\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding per-sample depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #depths_df = pd.read_parquet(\"/share/home/ychi/data/notebook/dailyT/sperm25/depth.parquet\")\n",
    "# depths_df = pd.read_parquet(\"/share/home/ychi/data/notebook/dailyT/sperm25/real_depth.parquet\")\n",
    "\n",
    "# agg.update(\n",
    "#     {\n",
    "#         \"mean_depth\" : (\"depth\",\"mean\")\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding centelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relpos = centelo_relpos(s2m_index(features.index), \"mm10\", dupref=True) # remember to set dupref=True\n",
    "relpos = centelo_relpos(s2m_index(features.index), \"mm10_dip\") # remember to set dupref=True\n",
    "relpos.columns = [\"chrom\",\"pos\",\"centelo\"]\n",
    "relpos = relpos.set_index([\"chrom\",\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "relpos = relpos.loc[~relpos.index.get_level_values(0).isin(\n",
    "    [\"chrX(mat)\",\"chrX(pat)\",\"chrY(mat)\",\"chrY(pat)\"])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([features,m2s_index(relpos)],axis=1,join=\"outer\").loc[features.index]\n",
    "agg.update(\n",
    "    {\"mean_centelo\" : (\"centelo\", \"mean\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding extrem centelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_index(inplace=True)\n",
    "features = s2m_index(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [0.5e6,1e6,2e6,5e6,10e6]\n",
    "p, q = False, True\n",
    "centelo = fetch_cent_chromlen(\"mm10_dip\")\n",
    "centelo_cols = []\n",
    "for dis in dists:\n",
    "    centelo_col = \"%.1f\" % (dis/1e6) + \"M_centelo\"\n",
    "    centelo_cols.append(centelo_col)\n",
    "    features = features.assign(**{centelo_col:0})\n",
    "    for chrom in centelo.index:\n",
    "        cent_start, cent_end = centelo.loc[chrom, [\"start\",\"end\"]]\n",
    "        # arm1 paracentric\n",
    "        if p:\n",
    "            features.loc[(chrom, cent_start-dis):(chrom, cent_start), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            # arm2 paracentric\n",
    "            features.loc[(chrom, cent_end):(chrom, cent_end+dis), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        start, end = 0, centelo.loc[chrom, \"chrom_length\"]\n",
    "        # arm1 near telomere\n",
    "        if p:\n",
    "            features.loc[(chrom, start):(chrom, start+dis), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            features.loc[(chrom, end-dis):(chrom, end), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"sum\") for i in centelo_cols]\n",
    "    ))\n",
    ")\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_mean_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"mean\") for i in centelo_cols]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = m2s_index(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add separate centelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_index(inplace=True)\n",
    "features = s2m_index(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [0.5e6,1e6,2e6,5e6,10e6]\n",
    "p, q = False, True\n",
    "centelo = fetch_cent_chromlen(\"mm10_dip\")\n",
    "centelo_cols = []\n",
    "for dis in dists:\n",
    "    centelo_col = \"%.1f\" % (dis/1e6) + \"M_cent\"\n",
    "    centelo_cols.append(centelo_col)\n",
    "    features = features.assign(**{centelo_col:0})\n",
    "    for chrom in centelo.index:\n",
    "        cent_start, cent_end = centelo.loc[chrom, [\"start\",\"end\"]]\n",
    "        # arm1 paracentric\n",
    "        if p:\n",
    "            features.loc[(chrom, cent_start-dis):(chrom, cent_start), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            # arm2 paracentric\n",
    "            features.loc[(chrom, cent_end):(chrom, cent_end+dis), centelo_col] = -1\n",
    "        else:\n",
    "            pass\n",
    "for dis in dists:\n",
    "    centelo_col = \"%.1f\" % (dis/1e6) + \"M_telo\"\n",
    "    centelo_cols.append(centelo_col)\n",
    "    features = features.assign(**{centelo_col:0})\n",
    "    for chrom in centelo.index:\n",
    "        start, end = 0, centelo.loc[chrom, \"chrom_length\"]\n",
    "        # arm1 near telomere\n",
    "        if p:\n",
    "            features.loc[(chrom, start):(chrom, start+dis), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "        if q:\n",
    "            features.loc[(chrom, end-dis):(chrom, end), centelo_col] = 1\n",
    "        else:\n",
    "            pass\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"sum\") for i in centelo_cols]\n",
    "    ))\n",
    ")\n",
    "agg.update(\n",
    "    dict(zip(\n",
    "        [centelo_col+\"_mean_dist\" for centelo_col in centelo_cols],\n",
    "        [(i,\"mean\") for i in centelo_cols]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = m2s_index(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(h.ddir/\"mm10_dip.features.csv.gz\")\n",
    "dump_pickle(agg,h.ddir/\"mm10_dip.aggs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
