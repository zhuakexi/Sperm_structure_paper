{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../head.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/cooltools/lib/numutils.py:11: FutureWarning: The `cooler.tools` module is deprecated in v0.9 and will be removed in v0.10. Use `cooler.parallel` instead.\n",
      "  from ._numutils import (\n",
      "/opt/conda/lib/python3.10/site-packages/cooltools/api/expected.py:12: FutureWarning: The `cooler.tools` module is deprecated in v0.9 and will be removed in v0.10. Use `cooler.parallel` instead.\n",
      "  from cooler.tools import partition\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from hic_basic.plot.hic import _plot_mat, cool2mat\n",
    "from hic_basic.coolstuff import cli_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IS2blocks(borders):\n",
    "    # prepare 0-1, 2-3, 4-5, ...\n",
    "    chunks = []\n",
    "    for i, chunk in borders.groupby(lambda x : x % 2):\n",
    "        chunks.append(chunk)\n",
    "    chunks[1].index = chunks[1].index - 1\n",
    "    tad_blocks0 = pd.concat(\n",
    "        [\n",
    "            chunks[0][[\"chrom\",\"start\"]],\n",
    "            chunks[1][[\"chrom\",\"start\"]]\n",
    "            ],\n",
    "        axis=1\n",
    "    )\n",
    "    tad_blocks0.columns = [\"chrom1\",\"start1\",\"chrom2\",\"start2\"]\n",
    "    # prepare 1-2, 3-4, 5-6, ...\n",
    "    chunks = []\n",
    "    for i, chunk in borders.groupby(lambda x : x % 2):\n",
    "        chunks.append(chunk)\n",
    "    chunks[0].index = chunks[0].index - 1\n",
    "    tad_blocks1 = pd.concat(\n",
    "        [\n",
    "            chunks[1][[\"chrom\",\"start\"]],\n",
    "            chunks[0][[\"chrom\",\"start\"]]\n",
    "            ],\n",
    "        axis=1\n",
    "    )\n",
    "    tad_blocks1.columns = [\"chrom1\",\"start1\",\"chrom2\",\"start2\"]\n",
    "    tad_blocks = pd.concat([tad_blocks0, tad_blocks1], axis=0).sort_index()\n",
    "    tad_blocks = tad_blocks.dropna(how=\"any\")\n",
    "    tad_blocks = tad_blocks.query(\"chrom1 == chrom2\").copy()\n",
    "    tad_blocks[\"start1\"] = tad_blocks[\"start1\"].astype(int)\n",
    "    tad_blocks[\"start2\"] = tad_blocks[\"start2\"].astype(int)\n",
    "    return tad_blocks\n",
    "# borders = ISs[\"Tan2018\"]\n",
    "# borders = borders.loc[borders[\"is_boundary_200000\"]].reset_index(drop=True)\n",
    "# IS2blocks(borders)\n",
    "# def TAD_pileup_strength(mat):\n",
    "#     \"\"\"\n",
    "#     Calculate the strength of TAD pileup.\n",
    "#     Input:\n",
    "#         mat: 2D numpy array\n",
    "#     \"\"\"\n",
    "#     # 30*30\n",
    "#     inter_tad = 0.5 * (mat[30:60,0:30].sum() + mat[60:90,30:60].sum())\n",
    "#     tad = mat[30:60,30:60].sum()\n",
    "#     strength = tad / inter_tad\n",
    "#     return strength\n",
    "def TAD_pileup_strength(mat, strip=3)->float:\n",
    "    \"\"\"\n",
    "    Calculate TAD strength from pileup matrix.\n",
    "    To remove influence from diagonal, we calculate region around domain loop.\n",
    "    The size of region is determined by strip.\n",
    "    Input:\n",
    "        mat: 2D numpy array\n",
    "        strip: min distance to diagonal, count by pixels\n",
    "    Output:\n",
    "        strength: float\n",
    "    \"\"\"\n",
    "    if isinstance(mat, pd.DataFrame):\n",
    "        mat = mat.values\n",
    "    e = strip\n",
    "    inter_tad_1 = mat[45+e:60,15+e:30]\n",
    "    inter_tad_2 = mat[60:75-e,30:45-e]\n",
    "    tad = mat[45+e:60,30:45-e]\n",
    "    strength = tad.sum() / (0.5 * (inter_tad_1.sum() + inter_tad_2.sum()))\n",
    "    #print(tad.sum(), inter_tad_1.sum(), inter_tad_2.sum())\n",
    "    return strength\n",
    "def cool2mat_OE(coolp, chrom, expected, balance=False):\n",
    "    \"\"\"\n",
    "    Fetch cooler matrix and calculate OE.\n",
    "    Input:\n",
    "        coolp: path to cooler\n",
    "        chrom: chromosome\n",
    "    \"\"\"\n",
    "    expected = expected.query('(region1 == @chrom) and (region2 == @chrom)')\n",
    "    if balance:\n",
    "        expected = expected[\n",
    "            [\"dist\",\"balanced.avg\"]\n",
    "            ].set_index(\"dist\")[\"balanced.avg\"].to_dict()\n",
    "    else:\n",
    "        expected = expected[\n",
    "            [\"dist\",\"count.avg\"]\n",
    "            ].set_index(\"dist\")[\"count.avg\"].to_dict()\n",
    "    raw_mat = cool2mat(coolp, chrom, balance=balance)\n",
    "    if isinstance(raw_mat.index, pd.MultiIndex):\n",
    "        raw_mat.index = raw_mat.index.get_level_values(1)\n",
    "    if isinstance(raw_mat.columns, pd.MultiIndex):\n",
    "        raw_mat.columns = raw_mat.columns.get_level_values(1)\n",
    "    exp_mat = np.zeros_like(raw_mat.values).astype(float)\n",
    "    for k, v in expected.items():\n",
    "        np.fill_diagonal(exp_mat[k:], v)\n",
    "        np.fill_diagonal(exp_mat[:,k:], v)\n",
    "    return (raw_mat / exp_mat).fillna(0)\n",
    "def add_diag_law(raw_mat, binsize=20000, power=0.25):\n",
    "    \"\"\"\n",
    "    Add artificial diagonal law to the matrix.\n",
    "    \"\"\"\n",
    "    w_mat = np.zeros_like(raw_mat.values).astype(float)\n",
    "    for k in range(0, raw_mat.shape[0]):\n",
    "        weight = (k * binsize + binsize)**(-power)\n",
    "        np.fill_diagonal(w_mat[k:], weight)\n",
    "        np.fill_diagonal(w_mat[:,k:], weight)\n",
    "    return raw_mat * w_mat\n",
    "def block_pileup(coolp, refs, expected=None, power=0.25, give_snips=False, balance=False):\n",
    "    \"\"\"\n",
    "    Fetch regions from cooler, iterate chrom by chrom.\n",
    "    Input:\n",
    "        coolp: path to cooler file\n",
    "        refs: list of (chrom, start, end)\n",
    "    \"\"\"\n",
    "    if all((i in tads.columns) for i in [\"chrom1\",\"start1\",\"start2\"]):\n",
    "        format = \"bedpe\"\n",
    "        chrom_col, start_col, end_col = \"chrom1\", \"start1\", \"start2\"\n",
    "    elif all((i in tads.columns) for i in [\"chrom\",\"start\",\"end\"]):\n",
    "        format =  \"bed\"\n",
    "        chrom_col, start_col, end_col = \"chrom\", \"start\", \"end\"\n",
    "    else:\n",
    "        raise ValueError(\"No chrom1/start1/start2 or chrom/start/end found\")\n",
    "    print(f\"ref is treated as {format}\")\n",
    "    chroms = tads[chrom_col].unique()\n",
    "    all_snips = []\n",
    "    for chrom, tad_chunk in tqdm(tads.groupby(chrom_col), desc=\"chrom\", total=len(chroms)):\n",
    "        if expected is not None:\n",
    "            chrom_mat = cool2mat_OE(str(coolp), chrom, expected, balance=balance)\n",
    "            chrom_mat = add_diag_law(chrom_mat, power=power)\n",
    "        else:\n",
    "            chrom_mat = cool2mat(str(coolp), chrom, balance=balance)\n",
    "        # NOTE: this is a temporary fix for the bug in cooler\n",
    "        chrom_mat = chrom_mat.loc[\n",
    "            ~chrom_mat.index.duplicated(keep=\"first\"),\n",
    "            ~chrom_mat.columns.duplicated(keep=\"first\")\n",
    "        ]\n",
    "        chrom_snips = []\n",
    "        for i, row in tad_chunk.iterrows():\n",
    "            start, end = row[start_col], row[end_col]\n",
    "            length = end - start\n",
    "            left = start-length if start-length > 0 else 0\n",
    "            #print(chrom_mat)\n",
    "            right = end+length if end+length < chrom_mat.index.max() else chrom_mat.index.max()\n",
    "            snip = chrom_mat.loc[left:right, left:right]\n",
    "            chrom_snips.append(snip)\n",
    "        all_snips.extend(chrom_snips)\n",
    "    #return chrom_snips\n",
    "    resize_snips = []\n",
    "    for snip in all_snips:\n",
    "        snip = snip.values\n",
    "        #snip = (snip - np.nanmean(snip)) / np.nanstd(snip)\n",
    "        #resize_snips.append(cv2.resize(snip, (100,100)))\n",
    "        resize_snips.append(skimage.transform.resize(\n",
    "            snip, (90,90), preserve_range=True\n",
    "            ))\n",
    "    mat = np.nanmean(np.array(resize_snips), axis=0)\n",
    "    if give_snips:\n",
    "        return mat, resize_snips, all_snips\n",
    "    else:\n",
    "        return mat\n",
    "def asymmetric_pileup(coolp, refs, expand, expected=None, binsize=None, power=0.25, give_snips=False, balance=False):\n",
    "    \"\"\"\n",
    "    Fetch any regions from cooler, iterate chrom by chrom.\n",
    "    TODO: support inter-chrom regions\n",
    "    Input:\n",
    "        coolp: path to cooler file\n",
    "        refs: list of (chrom1, start1, end1, chrom2, start2, end2)\n",
    "        expand: treat input refs as point, expand by expand bp\n",
    "        expected: path to expected file, will give OBS/EXP if provided\n",
    "        binsize: if provided, will use this to give index and columns for output matrix\n",
    "        power: power to add to the diagonal, use this to visualize near-diagonal features such as TADs\n",
    "        give_snips: return the snips used to calculate the pileup\n",
    "        balance: use balanced matrix\n",
    "    Output:\n",
    "        mat: pileup matrix\n",
    "    \"\"\"\n",
    "    if all((i in refs.columns) for i in [\"chrom1\",\"start1\",\"start2\",\"chrom2\",\"end1\",\"end2\"]):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Input refs should have columns: chrom1, start1, end1, chrom2, start2, end2\")\n",
    "    chroms = refs[\"chrom1\"].unique()\n",
    "    all_snips = []\n",
    "    skipped = 0\n",
    "    for chrom, ref_chunk in tqdm(refs.groupby(\"chrom1\"), desc=\"chrom\", total=len(chroms)):\n",
    "        if expected is not None:\n",
    "            chrom_mat = cool2mat_OE(str(coolp), chrom, expected, balance=balance)\n",
    "            if power is not None:\n",
    "                chrom_mat = add_diag_law(chrom_mat, power=power)\n",
    "        else:\n",
    "            chrom_mat = cool2mat(str(coolp), chrom, balance=balance)\n",
    "        # NOTE: this is a temporary fix for the bug in cooler\n",
    "        chrom_mat = chrom_mat.loc[\n",
    "            ~chrom_mat.index.duplicated(keep=\"first\"),\n",
    "            ~chrom_mat.columns.duplicated(keep=\"first\")\n",
    "        ]\n",
    "        chrom_snips = []\n",
    "        for i, row in ref_chunk.iterrows():\n",
    "            start1, end1, start2, end2 = row[[\"start1\",\"end1\",\"start2\",\"end2\"]]\n",
    "            left1, left2 = start1 - expand, start2 - expand\n",
    "            right1, right2 = end1 + expand, end2 + expand\n",
    "            if any([\n",
    "                left1 < 0,\n",
    "                left2 < 0,\n",
    "                right1 > chrom_mat.index.max(),\n",
    "                right2 > chrom_mat.columns.max()\n",
    "            ]):\n",
    "                skipped += 1\n",
    "                continue\n",
    "            snip = chrom_mat.loc[left1:right1, left2:right2]\n",
    "            chrom_snips.append(snip)\n",
    "        all_snips.extend(chrom_snips)\n",
    "    all_snip_values = [i.values for i in all_snips]\n",
    "    print(f\"Skipped {skipped} regions\")\n",
    "    mat = np.nanmean(np.array(all_snip_values), axis=0)\n",
    "    mat = pd.DataFrame(mat)\n",
    "    if binsize is not None:\n",
    "        mat.index = np.arange(-expand, expand+binsize+1, binsize)\n",
    "        mat.columns = np.arange(-expand, expand+binsize+1, binsize)\n",
    "    if give_snips:\n",
    "        return mat, all_snips\n",
    "    else:\n",
    "        return mat\n",
    "# borders = ISs[\"Tan2018\"]\n",
    "# borders = borders.loc[borders[\"is_boundary_200000\"]].reset_index(drop=True)\n",
    "# tads = IS2blocks(borders)\n",
    "# coolp = h.ddir / \"Sperm_hg.d3.proximity_map.mcool\"\n",
    "# coolp = str(coolp)+\"::/resolutions/20000\"\n",
    "# tads = tads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
